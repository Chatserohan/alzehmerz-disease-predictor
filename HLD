import tensorflow as tf 
from tensorflow import keras 
from keras import Sequential 
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten 

# Load training and validation datasets
train_ds = keras.utils.image_dataset_from_directory(
    directory = 'traindata',
    labels = 'inferred',
    label_mode = 'int',
    batch_size = 32,
    image_size = (256,256)
)

validation_ds = keras.utils.image_dataset_from_directory(
    directory = 'testdata',
    labels = 'inferred',
    label_mode = 'int',
    batch_size = 32,
    image_size = (256,256)
)

# Normalize the images
def process(image, label):
    image = tf.cast(image/255, tf.float32)
    return image, label 

train_ds = train_ds.map(process)
validation_ds = validation_ds.map(process)

# Create CNN model for classification
model = Sequential()

model.add(Conv2D(32, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(256,256,3)))
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))

model.add(Conv2D(64, kernel_size=(3,3), padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))

model.add(Conv2D(128, kernel_size=(3,3), padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))

model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.summary()

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_ds, epochs=5, validation_data=validation_ds)

# Save the model
model.save('drctorai.h5')

# Plot training and validation loss
import matplotlib.pyplot as plt 
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Predict single image
import cv2 

# Load and preprocess a test image
def predict_image(image_path):
    testimg = cv2.imread(image_path)
    testimg = cv2.resize(testimg, (256,256))
    testinput = testimg.reshape((1,256,256,3))
    prediction = model.predict(testinput)
    return prediction

# Example predictions
print(predict_image('testdata/AD/0ce036a7-c924-4799-ab23-71ae7a550cf0.jpg'))
print(predict_image('testdata/CN/ff03822c-7ae5-49b6-853d-2b373cc76895.jpg'))

# Evaluate on test dataset
from tensorflow.keras.preprocessing.image import ImageDataGenerator

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    'testdata',
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary'
)

test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# Confusion matrix and classification report
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Predictions and true labels
y_pred = model.predict(test_generator, steps=len(test_generator))
y_pred_classes = (y_pred > 0.5).astype("int32")
y_true = test_generator.classes

# Confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=test_generator.class_indices.keys(), 
            yticklabels=test_generator.class_indices.keys())
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Classification report
print(classification_report(y_true, y_pred_classes))
