### Low-Level Design Document for CNN Image Classification

#### **1. Dataset Loading and Preprocessing**
- **Training Dataset**: 
  - Directory: `traindata`
  - Labels inferred automatically.
  - Images resized to 256x256.
  - Batched with a size of 32.
- **Validation Dataset**: 
  - Directory: `testdata`
  - Same preprocessing as training dataset.
- **Normalization**: 
  - Pixel values normalized to the range [0, 1] using a function `process(image, label)`.

```python
train_ds = keras.utils.image_dataset_from_directory(
    directory='traindata',
    labels='inferred',
    label_mode='int',
    batch_size=32,
    image_size=(256, 256)
)

validation_ds = keras.utils.image_dataset_from_directory(
    directory='testdata',
    labels='inferred',
    label_mode='int',
    batch_size=32,
    image_size=(256, 256)
)

def process(image, label):
    image = tf.cast(image / 255, tf.float32)
    return image, label

train_ds = train_ds.map(process)
validation_ds = validation_ds.map(process)
```

#### **2. CNN Model Architecture**
- **Layer Details**:
  1. Convolutional Layer: 32 filters, kernel size (3,3), ReLU activation.
  2. MaxPooling Layer: Pool size (2,2), stride 2.
  3. Convolutional Layer: 64 filters, kernel size (3,3), ReLU activation.
  4. MaxPooling Layer: Pool size (2,2), stride 2.
  5. Convolutional Layer: 128 filters, kernel size (3,3), ReLU activation.
  6. MaxPooling Layer: Pool size (2,2), stride 2.
  7. Flatten Layer: Converts 2D data to 1D.
  8. Dense Layer: 128 neurons, ReLU activation.
  9. Dense Layer: 64 neurons, ReLU activation.
  10. Output Layer: 1 neuron, sigmoid activation for binary classification.

```python
model = Sequential([
    Conv2D(32, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(256,256,3)),
    MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'),
    Conv2D(64, kernel_size=(3,3), padding='valid', activation='relu'),
    MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'),
    Conv2D(128, kernel_size=(3,3), padding='valid', activation='relu'),
    MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.summary()
```

#### **3. Model Compilation and Training**
- **Optimizer**: Adam.
- **Loss Function**: Binary Crossentropy.
- **Metrics**: Accuracy.
- **Training**: 5 epochs using training and validation datasets.

```python
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(train_ds, epochs=5, validation_data=validation_ds)
model.save('drctorai.h5')
```

#### **4. Performance Visualization**
- **Loss Graphs**: Training vs Validation loss.

```python
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()
```

#### **5. Model Predictions**
- **Single Image Prediction**:
  - Image resized to 256x256.
  - Pixel values normalized.
  - Model returns prediction for binary classification (0 or 1).

```python
import cv2

def predict_image(image_path):
    testimg = cv2.imread(image_path)
    testimg = cv2.resize(testimg, (256,256))
    testinput = testimg.reshape((1,256,256,3))
    prediction = model.predict(testinput)
    return prediction

print(predict_image('testdata/AD/0ce036a7-c924-4799-ab23-71ae7a550cf0.jpg'))
print(predict_image('testdata/CN/ff03822c-7ae5-49b6-853d-2b373cc76895.jpg'))
```

#### **6. Model Evaluation**
- **Test Dataset**:
  - Images rescaled to [0, 1].
  - Batched and evaluated for loss and accuracy.
- **Confusion Matrix**: Visualized using seaborn.
- **Classification Report**: Precision, recall, and F1-score.

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    'testdata',
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary'
)

test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# Confusion Matrix
y_pred = model.predict(test_generator, steps=len(test_generator))
y_pred_classes = (y_pred > 0.5).astype("int32")
y_true = test_generator.classes

cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=test_generator.class_indices.keys(), 
            yticklabels=test_generator.class_indices.keys())
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Classification Report
print(classification_report(y_true, y_pred_classes))
```
